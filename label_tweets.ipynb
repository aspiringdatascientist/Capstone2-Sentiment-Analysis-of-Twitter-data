{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Labeling Tweets__\n",
    "\n",
    "To build a target variable column, i,e., to label the sentiment of the given text, we will compare several sentiment analyzer tools which are widely available for classifying the data.Through the remaining sections, we’ll compare and discuss classification results using several well-known NLP libraries in Python. The methods described below fall under five broad categories as below:\n",
    "VADER, Textblob, SentiWordNet lexicon from NTLK, StanfordCoreNLP, Afinn\n",
    "The Positive, Negative and Neutral scores represent the proportion of text that falls in these categories which have been normalized between -1(most negative) and +1 (most positive). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary modules\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the csv file as Pandas dataframe\n",
    "df = pd.read_csv(\"@tweets13.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13915, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of DataFrame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop All rows with missing values\n",
    "df = df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2013-08-09 18:06:33\n",
      "1   2010-09-02 06:23:41\n",
      "2   2010-03-19 20:44:09\n",
      "3   2017-01-14 18:40:51\n",
      "4   2007-06-25 13:17:17\n",
      "Name: Date of Tweet, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Convert the created_at column to np.datetime object\n",
    "df['Date of Tweet'] = pd.to_datetime(df['Date of Tweet'])\n",
    "\n",
    "# Print created_at to see new format\n",
    "print(df['Date of Tweet'].head())\n",
    "\n",
    "# Set the index of ds_tweets to created_at\n",
    "df.set_index('Date of Tweet', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date of Tweet</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-08-09 18:06:33</th>\n",
       "      <td>2013</td>\n",
       "      <td>Worked with Lila and Nate today at BGHS Online...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-09-02 06:23:41</th>\n",
       "      <td>2010</td>\n",
       "      <td>We did vote if you recall Hillary won the popu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-19 20:44:09</th>\n",
       "      <td>2010</td>\n",
       "      <td>Remember Impeachment is just as much pa of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-14 18:40:51</th>\n",
       "      <td>2017</td>\n",
       "      <td>Funny how Republicans like Nikki Haley suddenl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-06-25 13:17:17</th>\n",
       "      <td>2007</td>\n",
       "      <td>Is this the Electoral College vote</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     year                                         clean_text\n",
       "Date of Tweet                                                               \n",
       "2013-08-09 18:06:33  2013  Worked with Lila and Nate today at BGHS Online...\n",
       "2010-09-02 06:23:41  2010  We did vote if you recall Hillary won the popu...\n",
       "2010-03-19 20:44:09  2010  Remember Impeachment is just as much pa of the...\n",
       "2017-01-14 18:40:51  2017  Funny how Republicans like Nikki Haley suddenl...\n",
       "2007-06-25 13:17:17  2007                 Is this the Electoral College vote"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'] = df['clean_text'].astype(str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. SentiWordNet lexicon:__\n",
    "\n",
    "First let's label the tweets as either positive, negative or neutral using SentiWordNet lexicon. Words are associated with a sentiment score included between -1 and 1. Words are in the form lemma#PoS and are aligned with WordNet lists that include adjectives, nouns, verbs and adverbs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag, map_tag\n",
    "import time\n",
    "import nltk\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.tag import pos_tag,map_tag\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize \n",
    "\n",
    "pstem = PorterStemmer()\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "df_copy = df.copy()\n",
    "df_copy = df_copy.reset_index()\n",
    "def pos_senti(df_copy):#takes\n",
    "    li_swn=[]\n",
    "    li_swn_pos=[]\n",
    "    li_swn_neg=[]\n",
    "    missing_words=[]\n",
    "    for i in range(len(df_copy.index)):\n",
    "        text = df_copy.loc[i]['clean_text']\n",
    "        tokens = word_tokenize(str(text))\n",
    "        tagged_sent = pos_tag(tokens)\n",
    "        store_it = [(word, map_tag('en-ptb', 'universal', tag)) for word, tag in tagged_sent]\n",
    "        #print(\"Tagged Parts of Speech:\",store_it)\n",
    "\n",
    "        pos_total=0\n",
    "        neg_total=0\n",
    "        for word,tag in store_it:\n",
    "            if(tag=='NOUN'):\n",
    "                tag='n'\n",
    "            elif(tag=='VERB'):\n",
    "                tag='v'\n",
    "            elif(tag=='ADJ'):\n",
    "                tag='a'\n",
    "            elif(tag=='ADV'):\n",
    "                tag = 'r'\n",
    "            else:\n",
    "                tag='nothing'\n",
    "\n",
    "            if(tag!='nothing'):\n",
    "                concat = word+'.'+tag+'.01'\n",
    "                try:\n",
    "                    this_word_pos=swn.senti_synset(concat).pos_score()\n",
    "                    this_word_neg=swn.senti_synset(concat).neg_score()\n",
    "                    #print(word,tag,':',this_word_pos,this_word_neg)\n",
    "                except Exception as e:\n",
    "                    wor = lem.lemmatize(word)\n",
    "                    concat = wor+'.'+tag+'.01'\n",
    "                    # Checking if there's a possiblity of lemmatized word be accepted into SWN corpus\n",
    "                    try:\n",
    "                        this_word_pos=swn.senti_synset(concat).pos_score()\n",
    "                        this_word_neg=swn.senti_synset(concat).neg_score()\n",
    "                    except Exception as e:\n",
    "                        wor = pstem.stem(word)\n",
    "                        concat = wor+'.'+tag+'.01'\n",
    "                        # Checking if there's a possiblity of lemmatized word be accepted\n",
    "                        try:\n",
    "                            this_word_pos=swn.senti_synset(concat).pos_score()\n",
    "                            this_word_neg=swn.senti_synset(concat).neg_score()\n",
    "                        except:\n",
    "                            missing_words.append(word)\n",
    "                            continue\n",
    "                pos_total+=this_word_pos\n",
    "                neg_total+=this_word_neg\n",
    "        li_swn_pos.append(pos_total)\n",
    "        li_swn_neg.append(neg_total)\n",
    "\n",
    "        if(pos_total!=0 or neg_total!=0):\n",
    "            if(pos_total>neg_total):\n",
    "                li_swn.append(1)\n",
    "            else:\n",
    "                li_swn.append(-1)\n",
    "        else:\n",
    "            li_swn.append(0)\n",
    "    df_copy.insert(2,\"pos_score\",li_swn_pos,True)\n",
    "    df_copy.insert(3,\"neg_score\",li_swn_neg,True)\n",
    "    df_copy.insert(4,\"sent_score\",li_swn,True)\n",
    "    return df_copy\n",
    "    # end-of pos-tagging&sentiment\n",
    "df3 = pos_senti(df_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    6785\n",
       "-1    5264\n",
       " 0    1865\n",
       "Name: sent_score, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#counts of unique positive, negative and neutral values\n",
    "df3.sent_score.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. AFINN:__\n",
    "\n",
    "AFINN is a manually labeled by Finn Årup Nielsen in 2009–2011 list of English words rated for valence with an integer between minus five (negative) and plus five (positive) [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets: 13914\n",
      "Total tweets with sentiment: 13914\n",
      "positive tweets: 5615\n",
      "negative tweets: 3416\n",
      "neutral tweets: 4883\n"
     ]
    }
   ],
   "source": [
    "# Afinn sentiment LABELING\n",
    "from afinn import Afinn\n",
    "af = Afinn()\n",
    "count_total=0\n",
    "count_pos=0\n",
    "count_neut=0\n",
    "\n",
    "count_neg=0\n",
    "li_af = []\n",
    "for i in range(len(df_copy.index)):\n",
    "    sent = str(df_copy.loc[i]['clean_text'])\n",
    "    if(af.score(sent)>0):\n",
    "        count_pos=count_pos+1\n",
    "        count_total=count_total+1\n",
    "        li_af.append(1)\n",
    "    elif(af.score(sent)<0):\n",
    "        count_neg=count_neg+1\n",
    "        count_total=count_total+1\n",
    "        li_af.append(-1)\n",
    "    else:\n",
    "        li_af.append(0)\n",
    "        count_total=count_total+1\n",
    "        count_neut+=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Total tweets:\",len(df_copy.index))\n",
    "print(\"Total tweets with sentiment:\",count_total)\n",
    "print(\"positive tweets:\",count_pos)\n",
    "print(\"negative tweets:\",count_neg)\n",
    "print(\"neutral tweets:\",count_neut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. TextBlob:__\n",
    "\n",
    "TextBlob is a popular Python library for processing textual data. It is built on top of NLTK, another popular Natural Language Processing toolbox for Python. TextBlob uses a sentiment lexicon (consisting of predefined words) to assign scores for each word, which are then averaged out using a weighted average to give an overall sentence sentiment score. Three scores: “polarity”, “subjectivity” and “intensity” are calculated for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tweets: 13914\n",
      "Total tweets with sentiment: 13914\n",
      "positive tweets: 5820\n",
      "negative tweets: 2291\n",
      "neutral tweets: 5803\n"
     ]
    }
   ],
   "source": [
    "#TextBlob SENTIMENT LABELING\n",
    "from textblob import TextBlob\n",
    "count_total=0\n",
    "count_pos=0\n",
    "count_neg=0\n",
    "count_neut=0\n",
    "\n",
    "li_tb = []\n",
    "for i in range(len(df_copy.index)):\n",
    "    sent = TextBlob(str(df_copy.loc[i][\"clean_text\"]))\n",
    "    if(sent.sentiment.polarity>0):\n",
    "        count_pos=count_pos+1\n",
    "        count_total=count_total+1\n",
    "        li_tb.append(1)\n",
    "    elif(sent.sentiment.polarity<0):\n",
    "        count_neg=count_neg+1\n",
    "        count_total=count_total+1\n",
    "        li_tb.append(-1)\n",
    "    else:\n",
    "        li_tb.append(0)\n",
    "        count_neut+=1\n",
    "\n",
    "        count_total=count_total+1\n",
    "\n",
    "\n",
    "print(\"Total tweets:\",len(df_copy.index))\n",
    "print(\"Total tweets with sentiment:\",count_total)\n",
    "print(\"positive tweets:\",count_pos)\n",
    "print(\"negative tweets:\",count_neg)\n",
    "print(\"neutral tweets:\",count_neut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. VADER:__\n",
    "\n",
    "VADER (Valence Aware Dictionary and sentiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media.Once VADER is installed SentimentIntensityAnalyser object will be called to classify texts as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Convert the created_at column to np.datetime object\n",
    "df6 = df.copy()\n",
    "\n",
    "# Instantiate new SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Generate sentiment scores\n",
    "sentiment_scores = df6['clean_text'].apply(sid.polarity_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6[\"score\"] = sentiment_scores.apply(lambda x: x['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive tweets: 6123\n",
      "negative tweets: 3813\n",
      "neutral tweets: 3978\n"
     ]
    }
   ],
   "source": [
    "# Load SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "count_total=0\n",
    "count_pos=0\n",
    "count_neg=0\n",
    "count_neut=0\n",
    "\n",
    "\n",
    "for i in df6[\"score\"]:\n",
    "    if i >0:\n",
    "        count_pos=count_pos+1\n",
    "    elif i <0:\n",
    "        count_neg = count_neg +1\n",
    "    else:\n",
    "        count_neut = count_neut +1\n",
    "        \n",
    " \n",
    "\n",
    "print(\"positive tweets:\",count_pos)\n",
    "print(\"negative tweets:\",count_neg)\n",
    "print(\"neutral tweets:\",count_neut)\n",
    "conditions = [\n",
    "    (df6['score'] >0),\n",
    "    (df6['score'] <0),\n",
    "    (df6['score'] == 0)]\n",
    "choices = [1,-1,0]\n",
    "df6['sentiment'] = np.select(conditions, choices )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date of Tweet</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-08-09 18:06:33</th>\n",
       "      <td>2013</td>\n",
       "      <td>Worked with Lila and Nate today at BGHS Online...</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-09-02 06:23:41</th>\n",
       "      <td>2010</td>\n",
       "      <td>We did vote if you recall Hillary won the popu...</td>\n",
       "      <td>0.7579</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-03-19 20:44:09</th>\n",
       "      <td>2010</td>\n",
       "      <td>Remember Impeachment is just as much pa of the...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-14 18:40:51</th>\n",
       "      <td>2017</td>\n",
       "      <td>Funny how Republicans like Nikki Haley suddenl...</td>\n",
       "      <td>0.7766</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007-06-25 13:17:17</th>\n",
       "      <td>2007</td>\n",
       "      <td>Is this the Electoral College vote</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     year                                         clean_text  \\\n",
       "Date of Tweet                                                                  \n",
       "2013-08-09 18:06:33  2013  Worked with Lila and Nate today at BGHS Online...   \n",
       "2010-09-02 06:23:41  2010  We did vote if you recall Hillary won the popu...   \n",
       "2010-03-19 20:44:09  2010  Remember Impeachment is just as much pa of the...   \n",
       "2017-01-14 18:40:51  2017  Funny how Republicans like Nikki Haley suddenl...   \n",
       "2007-06-25 13:17:17  2007                 Is this the Electoral College vote   \n",
       "\n",
       "                      score  sentiment  \n",
       "Date of Tweet                           \n",
       "2013-08-09 18:06:33  0.6249          1  \n",
       "2010-09-02 06:23:41  0.7579          1  \n",
       "2010-03-19 20:44:09  0.0000          0  \n",
       "2017-01-14 18:40:51  0.7766          1  \n",
       "2007-06-25 13:17:17  0.0000          0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print few rows\n",
    "\n",
    "df6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5. StanfordCoreNLP:__\n",
    "    \n",
    "StanfordCoreNLP builds on grammatical structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycorenlp import StanfordCoreNLP\n",
    "nlp = StanfordCoreNLP('http://localhost:9000')\n",
    "\n",
    "df8 = df.copy()\n",
    "def get_sentiment(text):\n",
    "    res = nlp.annotate(text,\n",
    "                       properties={'annotators': 'sentiment,tokenize,ssplit',\n",
    "                                   'outputFormat': 'json',\n",
    "                                   'timeout': 1000,\n",
    "                       })\n",
    "    return res['sentences'][0]['sentiment']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative'"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_amb = \"We did vote if you recall Hillary won the popular vote by over million votes\"\n",
    "get_sentiment(text_amb)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Generate sentiment scores\n",
    "sentiment_scores = df8['clean_text'].apply(get_sentiment)\n",
    "df8[\"score\"] = sentiment_scores.apply(lambda x: x['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "df8[\"sentiment\"] =df8['clean_text'].map(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date of Tweet</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-08-09 18:06:33</th>\n",
       "      <td>2013</td>\n",
       "      <td>Worked with Lila and Nate today at BGHS Online Lab Great conversations regarding Electoral College and life after high</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-09-02 06:23:41</th>\n",
       "      <td>2010</td>\n",
       "      <td>We did vote if you recall Hillary won the popular vote by over million votes</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     year  \\\n",
       "Date of Tweet               \n",
       "2013-08-09 18:06:33  2013   \n",
       "2010-09-02 06:23:41  2010   \n",
       "\n",
       "                                                                                                                                 clean_text  \\\n",
       "Date of Tweet                                                                                                                                 \n",
       "2013-08-09 18:06:33  Worked with Lila and Nate today at BGHS Online Lab Great conversations regarding Electoral College and life after high   \n",
       "2010-09-02 06:23:41  We did vote if you recall Hillary won the popular vote by over million votes                                             \n",
       "\n",
       "                    sentiment  \n",
       "Date of Tweet                  \n",
       "2013-08-09 18:06:33  Negative  \n",
       "2010-09-02 06:23:41  Negative  "
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "df8.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative        7650\n",
       "Neutral         4941\n",
       "Positive        1300\n",
       "Verynegative    20  \n",
       "Verypositive    3   \n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8.sentiment.value_counts( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We did vote if you recall Hillary won the popular vote by over million votes'"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8[\"clean_text\"].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "year          int64 \n",
       "clean_text    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    (df8['sentiment'] == 'Negative'),\n",
    "    (df8['sentiment'] == 'Verynegative'),\n",
    "    (df8['sentiment']== \"Positive\"),\n",
    "    (df8['sentiment'] == \"Verypositive\" ),\n",
    "    (df8['sentiment']== \"Neutral\")\n",
    "]\n",
    "\n",
    "choices = [-1,-1,1,1,0]\n",
    "df8['sentiment_val'] = np.select(conditions, choices )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's compare all the sentiment analyzer tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StanfordCoreNLP:\n",
      "Date of Tweet    2017-01-14 18:40:51                                                                                               \n",
      "year             2017                                                                                                              \n",
      "clean_text       Funny how Republicans like Nikki Haley suddenly have all this energy for letting the people decide Trump fate when\n",
      "sentiment        Negative                                                                                                          \n",
      "sentiment_val    -1                                                                                                                \n",
      "Name: 3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"StanfordCoreNLP:\")\n",
    "print(df8.iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vader:\n",
      "year          2017                                                                                                              \n",
      "clean_text    Funny how Republicans like Nikki Haley suddenly have all this energy for letting the people decide Trump fate when\n",
      "score         0.7766                                                                                                            \n",
      "sentiment     1                                                                                                                 \n",
      "Name: 2017-01-14 18:40:51, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Vader:\")\n",
    "print(df6.iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentiWordNet lexicon:\n",
      "year          2017                                                                                                              \n",
      "clean_text    Funny how Republicans like Nikki Haley suddenly have all this energy for letting the people decide Trump fate when\n",
      "score         0.7766                                                                                                            \n",
      "sentiment     1                                                                                                                 \n",
      "Name: 2017-01-14 18:40:51, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"SentiWordNet lexicon:\")\n",
    "print(df6.iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob:\n",
      "Date of Tweet    2017-01-14 18:40:51                                                                                               \n",
      "year             2017                                                                                                              \n",
      "pos_score        0.25                                                                                                              \n",
      "neg_score        0                                                                                                                 \n",
      "sent_score       1                                                                                                                 \n",
      "clean_text       Funny how Republicans like Nikki Haley suddenly have all this energy for letting the people decide Trump fate when\n",
      "Name: 3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"TextBlob:\")\n",
    "print(df_copy.iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Afinn:\n",
      "Date of Tweet    2017-01-14 18:40:51                                                                                               \n",
      "year             2017                                                                                                              \n",
      "pos_score        0.25                                                                                                              \n",
      "neg_score        0                                                                                                                 \n",
      "sent_score       1                                                                                                                 \n",
      "clean_text       Funny how Republicans like Nikki Haley suddenly have all this energy for letting the people decide Trump fate when\n",
      "Name: 3, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Afinn:\")\n",
    "print(df3.iloc[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df8.to_csv(\"@tweets_final.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Conclusion:__\n",
    "\n",
    "StanfordCoreNLP will be used to label our tweets dataset since it is designed to help evaluate a model’s ability to understand representations of sentence structure, rather than just looking at individual words in isolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
